# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---

blueprint_name: sycomp-storage-slurm

vars:
  project_id: ""                   ## Set GCP Project ID Here
  deployment_name: "sycomp-slurm"  ## Set a customized deployment name
  region: ""                       ## Set region
  zone: ""                         ## Set zone
  nfs_dir: "/gpfs/fs1/export1"     ## Set the directory to export

# Documentation for each of the modules used below can be found at
# https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/main/modules/README.md

deployment_groups:
- group: primary
  modules:

  ## Create network shared between sycomp storage cluster slurm cluster
  - id: network1
    source: modules/network/vpc
    settings:
      network_name: ""           ## Set network name
      subnetwork_name: ""        ## Set subnetwork name
      # Source ip ranges for ssh, for example: [21.32.32.0/24].
      # In order to be able to login to the login node via ssh, the ip address
      # of this machine needs to be placed in the allowed_ssh_ip_ranges.
      allowed_ssh_ip_ranges: []

  - id: sycomp-scale-gcp
    source: "git::https://gitlab.com/sycomp/cluster-toolkit.git//sycomp-scale?ref=v1.0.0"
    use: [network1]
    settings:
      security:
        ssh:
          ssh_user_name: ""                   ## Set user name to ssh mgmt node, for example: "sycompacct"
          private_key: ""                     ## Set private key file, for example: ~/.ssh/id_rsa
          public_key: ""                      ## Set public key file, for example: ~/.ssh/id_rsa.pub
        customer_token:
          token: ""                           ## Set Your Customer Token
      scale_config:
        scale_node_count: 3                   ## Number of storage nodes to deploy
        scale_machine_type: "c3-standard-44"  ## Instance type of the storage nodes
        scale_volumes:
          data-storage:
            count: 4                          ## Number of disks to configure on each storage node
            size_in_gb: 250                   ## Size of each disk
            type: "hyperdisk-balanced"        ## Type of persistent disk to use
            provisioned_iops: 30000           ## Provisioned IOPS per disk, required for Hyperdisk
            provisioned_throughput: 500       ## Provisioned Throughput in MiB/sec per disk, required for Hyperdisk

      ces_config:
        enabled: true                         ## A value of true enables NFS service
        create_dns: true                      ## Create a round robin DNS entry that include all of the NFS Servers, one NFS server is created on each storage node.
      nfs_exports:
      - path: $(vars.nfs_dir)
        clients:
        - no_root_squash: false               ## Enable root squashing (secure default). Set to true to disable.

  ## Set up slurm cluster and configure NFS client
  - id: compute_nodeset
    source: community/modules/compute/schedmd-slurm-gcp-v6-nodeset
    use: [network1]
    settings:
      node_count_dynamic_max: 4
      machine_type: n2-standard-2
      allow_automatic_updates: false

  - id: compute_partition
    source: community/modules/compute/schedmd-slurm-gcp-v6-partition
    use:
    - compute_nodeset
    settings:
      is_default: true
      partition_name: compute

  - id: slurm_login
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-login
    use: [network1]
    settings:
      machine_type: n2-standard-4
      enable_login_public_ips: true

  - id: slurm_controller
    source: community/modules/scheduler/schedmd-slurm-gcp-v6-controller
    use:
    - network1
    - compute_partition
    - slurm_login
    settings:
      enable_controller_public_ips: true
      network_storage:
      ## Setup NFS client to mount sycomp storage NFS server
      - server_ip: $(sycomp-scale-gcp.nfs_server.dns_name)
        remote_mount: $(vars.nfs_dir)
        mount_options: "vers=4,nconnect=16,rsize=1048576,wsize=1048576"
        local_mount: "/nfs/sycomp"
        fs_type: nfs
